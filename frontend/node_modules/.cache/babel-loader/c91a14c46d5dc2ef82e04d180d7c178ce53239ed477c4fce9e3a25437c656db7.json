{"ast":null,"code":"// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../core/resource.mjs\";\nimport { buildHeaders } from \"../../internal/headers.mjs\";\nimport { path } from \"../../internal/utils/path.mjs\";\nexport class Calls extends APIResource {\n  /**\n   * Accept an incoming SIP call and configure the realtime session that will handle\n   * it.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.accept('call_id', {\n   *   type: 'realtime',\n   * });\n   * ```\n   */\n  accept(callID, body, options) {\n    return this._client.post(path`/realtime/calls/${callID}/accept`, {\n      body,\n      ...options,\n      headers: buildHeaders([{\n        Accept: '*/*'\n      }, options?.headers])\n    });\n  }\n  /**\n   * End an active Realtime API call, whether it was initiated over SIP or WebRTC.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.hangup('call_id');\n   * ```\n   */\n  hangup(callID, options) {\n    return this._client.post(path`/realtime/calls/${callID}/hangup`, {\n      ...options,\n      headers: buildHeaders([{\n        Accept: '*/*'\n      }, options?.headers])\n    });\n  }\n  /**\n   * Transfer an active SIP call to a new destination using the SIP REFER verb.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.refer('call_id', {\n   *   target_uri: 'tel:+14155550123',\n   * });\n   * ```\n   */\n  refer(callID, body, options) {\n    return this._client.post(path`/realtime/calls/${callID}/refer`, {\n      body,\n      ...options,\n      headers: buildHeaders([{\n        Accept: '*/*'\n      }, options?.headers])\n    });\n  }\n  /**\n   * Decline an incoming SIP call by returning a SIP status code to the caller.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.reject('call_id');\n   * ```\n   */\n  reject(callID, body = {}, options) {\n    return this._client.post(path`/realtime/calls/${callID}/reject`, {\n      body,\n      ...options,\n      headers: buildHeaders([{\n        Accept: '*/*'\n      }, options?.headers])\n    });\n  }\n}","map":{"version":3,"names":["APIResource","buildHeaders","path","Calls","accept","callID","body","options","_client","post","headers","Accept","hangup","refer","reject"],"sources":["C:\\Users\\Prana\\Desktop\\mira\\frontend\\node_modules\\openai\\src\\resources\\realtime\\calls.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as RealtimeAPI from './realtime';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Calls extends APIResource {\n  /**\n   * Accept an incoming SIP call and configure the realtime session that will handle\n   * it.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.accept('call_id', {\n   *   type: 'realtime',\n   * });\n   * ```\n   */\n  accept(callID: string, body: CallAcceptParams, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/accept`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * End an active Realtime API call, whether it was initiated over SIP or WebRTC.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.hangup('call_id');\n   * ```\n   */\n  hangup(callID: string, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/hangup`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Transfer an active SIP call to a new destination using the SIP REFER verb.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.refer('call_id', {\n   *   target_uri: 'tel:+14155550123',\n   * });\n   * ```\n   */\n  refer(callID: string, body: CallReferParams, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/refer`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Decline an incoming SIP call by returning a SIP status code to the caller.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.reject('call_id');\n   * ```\n   */\n  reject(\n    callID: string,\n    body: CallRejectParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/reject`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n}\n\nexport interface CallAcceptParams {\n  /**\n   * The type of session to create. Always `realtime` for the Realtime API.\n   */\n  type: 'realtime';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeAPI.RealtimeAudioConfig;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06';\n\n  /**\n   * The set of modalities the model can respond with. It defaults to `[\"audio\"]`,\n   * indicating that the model will respond with audio plus a transcript. `[\"text\"]`\n   * can be used to make the model respond with text only. It is not possible to\n   * request both `text` and `audio` at the same time.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: RealtimeAPI.RealtimeToolChoiceConfig;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: RealtimeAPI.RealtimeToolsConfig;\n\n  /**\n   * Realtime API can write session traces to the\n   * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n   * tracing is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: RealtimeAPI.RealtimeTracingConfig | null;\n\n  /**\n   * When the number of tokens in a conversation exceeds the model's input token\n   * limit, the conversation be truncated, meaning messages (starting from the\n   * oldest) will not be included in the model's context. A 32k context model with\n   * 4,096 max output tokens can only include 28,224 tokens in the context before\n   * truncation occurs.\n   *\n   * Clients can configure truncation behavior to truncate with a lower max token\n   * limit, which is an effective way to control token usage and cost.\n   *\n   * Truncation will reduce the number of cached tokens on the next turn (busting the\n   * cache), since messages are dropped from the beginning of the context. However,\n   * clients can also configure truncation to retain messages up to a fraction of the\n   * maximum context size, which will reduce the need for future truncations and thus\n   * improve the cache rate.\n   *\n   * Truncation can be disabled entirely, which means the server will never truncate\n   * but would instead return an error if the conversation exceeds the model's input\n   * token limit.\n   */\n  truncation?: RealtimeAPI.RealtimeTruncation;\n}\n\nexport interface CallReferParams {\n  /**\n   * URI that should appear in the SIP Refer-To header. Supports values like\n   * `tel:+14155550123` or `sip:agent@example.com`.\n   */\n  target_uri: string;\n}\n\nexport interface CallRejectParams {\n  /**\n   * SIP response code to send back to the caller. Defaults to `603` (Decline) when\n   * omitted.\n   */\n  status_code?: number;\n}\n\nexport declare namespace Calls {\n  export {\n    type CallAcceptParams as CallAcceptParams,\n    type CallReferParams as CallReferParams,\n    type CallRejectParams as CallRejectParams,\n  };\n}\n"],"mappings":"AAAA;SAESA,WAAW,QAAE;SAIbC,YAAY,QAAE;SAEdC,IAAI,QAAE;AAEf,OAAM,MAAOC,KAAM,SAAQH,WAAW;EACpC;;;;;;;;;;;EAWAI,MAAMA,CAACC,MAAc,EAAEC,IAAsB,EAAEC,OAAwB;IACrE,OAAO,IAAI,CAACC,OAAO,CAACC,IAAI,CAACP,IAAI,mBAAmBG,MAAM,SAAS,EAAE;MAC/DC,IAAI;MACJ,GAAGC,OAAO;MACVG,OAAO,EAAET,YAAY,CAAC,CAAC;QAAEU,MAAM,EAAE;MAAK,CAAE,EAAEJ,OAAO,EAAEG,OAAO,CAAC;KAC5D,CAAC;EACJ;EAEA;;;;;;;;EAQAE,MAAMA,CAACP,MAAc,EAAEE,OAAwB;IAC7C,OAAO,IAAI,CAACC,OAAO,CAACC,IAAI,CAACP,IAAI,mBAAmBG,MAAM,SAAS,EAAE;MAC/D,GAAGE,OAAO;MACVG,OAAO,EAAET,YAAY,CAAC,CAAC;QAAEU,MAAM,EAAE;MAAK,CAAE,EAAEJ,OAAO,EAAEG,OAAO,CAAC;KAC5D,CAAC;EACJ;EAEA;;;;;;;;;;EAUAG,KAAKA,CAACR,MAAc,EAAEC,IAAqB,EAAEC,OAAwB;IACnE,OAAO,IAAI,CAACC,OAAO,CAACC,IAAI,CAACP,IAAI,mBAAmBG,MAAM,QAAQ,EAAE;MAC9DC,IAAI;MACJ,GAAGC,OAAO;MACVG,OAAO,EAAET,YAAY,CAAC,CAAC;QAAEU,MAAM,EAAE;MAAK,CAAE,EAAEJ,OAAO,EAAEG,OAAO,CAAC;KAC5D,CAAC;EACJ;EAEA;;;;;;;;EAQAI,MAAMA,CACJT,MAAc,EACdC,IAAA,GAA4C,EAAE,EAC9CC,OAAwB;IAExB,OAAO,IAAI,CAACC,OAAO,CAACC,IAAI,CAACP,IAAI,mBAAmBG,MAAM,SAAS,EAAE;MAC/DC,IAAI;MACJ,GAAGC,OAAO;MACVG,OAAO,EAAET,YAAY,CAAC,CAAC;QAAEU,MAAM,EAAE;MAAK,CAAE,EAAEJ,OAAO,EAAEG,OAAO,CAAC;KAC5D,CAAC;EACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}