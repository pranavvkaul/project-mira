{"ast":null,"code":"// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../core/resource.mjs\";\nimport * as SpeechAPI from \"./speech.mjs\";\nimport { Speech } from \"./speech.mjs\";\nimport * as TranscriptionsAPI from \"./transcriptions.mjs\";\nimport { Transcriptions } from \"./transcriptions.mjs\";\nimport * as TranslationsAPI from \"./translations.mjs\";\nimport { Translations } from \"./translations.mjs\";\nexport class Audio extends APIResource {\n  constructor() {\n    super(...arguments);\n    this.transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n    this.translations = new TranslationsAPI.Translations(this._client);\n    this.speech = new SpeechAPI.Speech(this._client);\n  }\n}\nAudio.Transcriptions = Transcriptions;\nAudio.Translations = Translations;\nAudio.Speech = Speech;","map":{"version":3,"names":["APIResource","SpeechAPI","Speech","TranscriptionsAPI","Transcriptions","TranslationsAPI","Translations","Audio","constructor","transcriptions","_client","translations","speech"],"sources":["C:\\Users\\Prana\\Desktop\\mira\\frontend\\node_modules\\openai\\src\\resources\\audio\\audio.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as SpeechAPI from './speech';\nimport { Speech, SpeechCreateParams, SpeechModel } from './speech';\nimport * as TranscriptionsAPI from './transcriptions';\nimport {\n  Transcription,\n  TranscriptionCreateParams,\n  TranscriptionCreateParamsNonStreaming,\n  TranscriptionCreateParamsStreaming,\n  TranscriptionCreateResponse,\n  TranscriptionDiarized,\n  TranscriptionDiarizedSegment,\n  TranscriptionInclude,\n  TranscriptionSegment,\n  TranscriptionStreamEvent,\n  TranscriptionTextDeltaEvent,\n  TranscriptionTextDoneEvent,\n  TranscriptionTextSegmentEvent,\n  TranscriptionVerbose,\n  TranscriptionWord,\n  Transcriptions,\n} from './transcriptions';\nimport * as TranslationsAPI from './translations';\nimport {\n  Translation,\n  TranslationCreateParams,\n  TranslationCreateResponse,\n  TranslationVerbose,\n  Translations,\n} from './translations';\n\nexport class Audio extends APIResource {\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\n}\n\nexport type AudioModel =\n  | 'whisper-1'\n  | 'gpt-4o-transcribe'\n  | 'gpt-4o-mini-transcribe'\n  | 'gpt-4o-transcribe-diarize';\n\n/**\n * The format of the output, in one of these options: `json`, `text`, `srt`,\n * `verbose_json`, `vtt`, or `diarized_json`. For `gpt-4o-transcribe` and\n * `gpt-4o-mini-transcribe`, the only supported format is `json`. For\n * `gpt-4o-transcribe-diarize`, the supported formats are `json`, `text`, and\n * `diarized_json`, with `diarized_json` required to receive speaker annotations.\n */\nexport type AudioResponseFormat = 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt' | 'diarized_json';\n\nAudio.Transcriptions = Transcriptions;\nAudio.Translations = Translations;\nAudio.Speech = Speech;\n\nexport declare namespace Audio {\n  export { type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Transcriptions as Transcriptions,\n    type Transcription as Transcription,\n    type TranscriptionDiarized as TranscriptionDiarized,\n    type TranscriptionDiarizedSegment as TranscriptionDiarizedSegment,\n    type TranscriptionInclude as TranscriptionInclude,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionStreamEvent as TranscriptionStreamEvent,\n    type TranscriptionTextDeltaEvent as TranscriptionTextDeltaEvent,\n    type TranscriptionTextDoneEvent as TranscriptionTextDoneEvent,\n    type TranscriptionTextSegmentEvent as TranscriptionTextSegmentEvent,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n    type TranscriptionCreateParamsNonStreaming as TranscriptionCreateParamsNonStreaming,\n    type TranscriptionCreateParamsStreaming as TranscriptionCreateParamsStreaming,\n  };\n\n  export {\n    Translations as Translations,\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n\n  export { Speech as Speech, type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n"],"mappings":"AAAA;SAESA,WAAW,QAAE;OACf,KAAKC,SAAS;SACZC,MAAM,QAAmC;OAC3C,KAAKC,iBAAiB;SAiB3BC,cAAc,QACf;OACM,KAAKC,eAAe;SAMzBC,YAAY,QACb;AAED,OAAM,MAAOC,KAAM,SAAQP,WAAW;EAAtCQ,YAAA;;IACE,KAAAC,cAAc,GAAqC,IAAIN,iBAAiB,CAACC,cAAc,CAAC,IAAI,CAACM,OAAO,CAAC;IACrG,KAAAC,YAAY,GAAiC,IAAIN,eAAe,CAACC,YAAY,CAAC,IAAI,CAACI,OAAO,CAAC;IAC3F,KAAAE,MAAM,GAAqB,IAAIX,SAAS,CAACC,MAAM,CAAC,IAAI,CAACQ,OAAO,CAAC;EAC/D;;AAiBAH,KAAK,CAACH,cAAc,GAAGA,cAAc;AACrCG,KAAK,CAACD,YAAY,GAAGA,YAAY;AACjCC,KAAK,CAACL,MAAM,GAAGA,MAAM","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}